# Don't Block the Event Loop(or the Worker Pool)

[原文](https://nodejs.org/en/docs/guides/dont-block-the-event-loop/)

## 你需要阅读此指南吗

如果你正在写一些复杂的代码，而不是一个简单的命令行脚本，阅读此指南将对你编写高性能、更安全的应用提供帮助。这篇文章是从node服务器的脚本写的，但其中的概念同样适用于复杂的node应用，因为不同操作系统在细节方面不同，本文中提到的操作系统均指Linux

## 概要

node.js在事件循环中执行js代码(初始化以及回调)，并提供一个工作线程池来处理开销大的任务，比如文件I/O，node.js具有很好的伸缩性，有些时候比像Apache等重量级方案要好。而node.js伸缩性的秘诀就在于使用少量的线程来处理大量的客户端请求。如果node.js可以使用更少的线程，那么它可以将更多的系统时间和内存投入到处理客户端请求上，而不是在线程上消耗空间和时间(内存分配，上下文切换)。但因为node.js使用的线程很少，所以你必须合理的使用它们来组织你的应用。

这里提供一个保持你的node服务快速高效的经验法则：当任意给定时间内与每个客户端关联的工作都是“小”任务时，node的速度是很快的。这个法则可以应用到事物循环中的回调以及工作线程池中的任务。

## 为什我需要避免阻塞事件循环和工作线程池

node.js使用少量线程来处理大量的客户端。在node中有两种类型的线程：一个事件循环(也就是所说的主线程、事件线程等)，以及一个由k个工作线程组成的工作线程池。如果一个线程正在执行一个耗时很长的回调(在事件循环中)或任务(在工作线程上)，我们就称之为被阻塞了。当一个线程因为处理某个客户端的请求而被阻塞时，它就无法处理来自其它客户端的请求。这就为不阻塞事件循环和工作线程池提供了两个理由：

1. 性能：如果经常在任意一种类型的线程上执行重量级的活动，这将会影响你系统的吞吐量
2. 安全性：如果存在对于特定的输入会导致你的线程被阻塞的可能性，那么攻击者就可以利用这个来使你的所有线程都被阻塞，从而无法为其它客户端提供服务，这也就是所谓的“拒绝服务攻击”。

## Node 概览

> Node uses the Event-Driven Architecture: it has an Event Loop for orchestration and a Worker Pool for expensive tasks.
> Node使用事件驱动的架构：用事件循环来进行任务的编排，使用工作线程池来执行昂贵（I/O，网络等耗时长）任务

### 哪些代码运行在事循环中

当Node应用运行时，首先会进行一个初始化的阶段，进行模块的引入以及注册事件的回调函数，然后便进入事件循环，通过执行对应的回调函数来响应来自客户端的请求。回调函数是同步执行的，并可能注册异步请求来继续后续的处理，这些请求也会在事件循环中执行。

对于回调函数创建的非阻塞异步请求（比如网络请求）也会由事件循环来执行。

总而言之，事件循环执行事件注册的JavaScript回调，并且还负责实现非阻塞异步请求，例如网络I/O。

### 哪些代码运行在工作线程池中

Node的工作线程池是在libuv实现的，它提供通用的任务提交API。

Node使用工作线程池来处理一些昂贵的任务，这包括像系统底层没有提供非阻塞版本的I/O操作以及某些CPU密集型的任务。

以下这些Node模块的API是利用工作线程池来实现：

1. I/O密集型：
	* DNS：dns.lookup()，dns.lookupService()。
	* 文件系统：除了fs.FSWatcher()以及那些显示同步使用libuv线程池之外的所有文件系统API。
2. CPU密集型：
	* Crypto：crypto.pbkdf2(), crypto.scrypt(), crypto.randomBytes(), crypto.randomFill(), crypto.generateKeyPair()。
	* Zlib：除了显示同步使用libuv线程池之外的所有zlib的API。

在很多Node应用中，这些API是使用工作线程池的任务的唯一来源。一些使用C++附加组件的应用及模块可以提交其它任务到工作线程池中。

为完整起见，我们注意到在事件循环的回调中调用这些API时，会调用C++Bindings来提交任务到工作线程池，但此过程带来的开销相对整个任务的开销可以忽略不计。当提交任务到工作线程池中时，Node会提供一个指针指向C++Bindings中对应的C++函数。

### Node是如何决定下一步执行什么代码

从抽象层面来说，事件循环和工作线程池各自维护一个挂起事件的队列和挂起的任务的队列。

但事实上，事件循环并没有维护一个队列，而是维护了一个文件描述符的集合，Node通知操作系统监听这些文件描述符状态的变化，不同的操作系统使用不同的机制来实现监听，比如Linux下的epoll，OSX下的kqueue，Solaris下的事件端口以及Windows下的IOCP，这些文件描述符对应于网络套接字以及任何监听的文件。当操作系统通知某一个文件描述符的状态变更为ready时，事件循环就会将其转换为对应的事件并触发与此事件关联的回调函数。

相比之下，工作线程池使用一个真实的队列来保存需要处理的任务。每个工作线程从队列的顶部获取任务并处理。当处理完成时，工作线程会为事件循环触发一个“至少有一个任务已完成”的事件。

### 这对应用程序的设计意味着什么

对于像Apache这样一个客户端对应一个工作线程的系统，每一个挂起的客户端都分配了一个自己的线程。如果此线程阻塞了，操作系统会中断它，转而处理另一个客户端的请求。因此，操作系统可以确保那些需要少量工作的客户端请求不会被那些需要大量工作处理的客户端请求所影响。

但由于Node只使用少量的线程来处理客户端请求，如果某一个处理客户端请求的线程被阻塞了，则其它被挂起的客户端请求在此线程完成之前都不会被处理。所以如何保证客户端请求被均衡处理的责任就交给你的应用本身了。这意味着在单个的回调或任务中，你不应当为单个客户端请求做太多的工作。

这就是Node可以很好地扩展的部分原因，但也意味着确保均衡调度的工作交给你自己。下一节内容就是讨论如何为事件循环以及工作线程池提供均衡的调度。

## 不要阻塞事件循环

对于每一个新的客户端连接，事件循环会产生一个通知，并安排响应内容的生成。所有请求及响应都会经过事件循环，这也就意味着如果事循环在某个点上耗时过多，那所有当前已连接的客户端及新的客户端请求都将得不到处理。

因此你需要保证决不阻塞事件循环，换言之，你的每一个javascript回调务必快速的完成，这当然也包括你的await、Promise.then等处理过程。

确保这点的一个好的方法就是推断出你回调函数的计算复杂度。如果无论参数是什么，你的回调函数总是有一个常量的执行步骤，那么就可以给每个挂起的客户端一个均衡的处理机会。如果你的回调函数的执行步骤依赖于参数（比如O(n)、O(n^2)），那你可能需要考虑一下参数可能有多长。

### 你应该如何小心

Node使用谷歌的V8引擎来执行javascript，对于一般的操作，它的执行速度相当快。但对下面要讨论的正则及JSON相关的操作是个例外。

然后，对于复杂的任务你应当考虑限制输入并且拒绝太长的输入。这样，即使你的回调非常复杂，但通过限制输入，也可以保证在最长可接受的输入情况下，回调不会比最坏的情况下的耗时更长，然后可以评估此回调的最杯情况下的耗时并决定在你的上下文中它是否可接受。

### 阻塞事件循环：REDOS(Regular expression Denial of Service——正则表达式拒绝服务攻击)

[ReDoS原理](https://www.freebuf.com/articles/network/124422.html)

一种常见的阻塞事件循环的方式是使用易受攻击或是有缺陷的正则表达式，这带来的影响往往是毁灭性的。

正则表达式使用一个给定的模式来匹配输入的字符串，我们通常会以为正则表达式是将输入的字符串一次性扫描来对它来进行匹配，所以它的执行耗时是O(n)，n则为输入字符串的长度。在大多数情况，它确实如此。但不幸的是，在一些场景下，正则匹配时会对输入的字符串进行指数次的扫描，时间复杂度为O(2^n)。这也就意味着，如果原匹配需要扫描的次数是x，那输入字符数仅多增加一个字符时，扫描的次数就变成2x。而扫描次数与执行耗时是线性相关的，所以它执行的结果就是阻塞事件循环。

所谓易受攻击的表达式，对于一些错误的输入会让你的正则表达式引擎执行时间复杂度为O(2^n)。如何判断你的正则表达式是否是易受攻击的是一个比较难回答的问题，而且根据你使用的语言(Perl，Python，Ruby，Java，Javascript等)的不同也不一样。但也有一些对于所有语言都适用的规范原则。

1. 避免嵌套量词，比如(a+)*，Node的正则引擎对于这种模式，部分情况下能处理得较快，但其它语言的处理较慢。
2. 避免对重复的子句使用OR，比如(a|a)*，同样，这种模式，仅部分情况会处理得比较快。
3. 避免使用反向引用，比如(a.*)\1，没有哪个正则引擎能保证执行时间是线性的。
4. 如果只是进行简单的字符串匹配，使用indexOf或本地的等于操作符，它的耗时会更少，并且不会超过O(n)

如果你不确定你的正则表达式是否是易受攻击的，只要记住，对于判断是否存在匹配时，即使是易受攻击的正则表达式，输入了一个很长的字符串，对于Node而言也不会有问题，但如果是判断是否存在不匹配，而Node必须尝试所有的匹配路径才能确定，此时才会出现指数次的扫描。

#### 一个REDOS的例子

下面这个例子就是一个易受攻击的正则表达式，会将服务暴露到被REDOS攻击的风险中

```javascript
app.get('/redos-me', (req, res) => {
  let filePath = req.query.filePath;

  // REDOS
  if (filePath.match(/(\/.+)+$/)) {
    console.log('valid path');
  }
  else {
    console.log('invalid path');
  }

  res.sendStatus(200);
});
```

这里用来检查Linux下有效路径的正则就是一个有缺陷的正则，它的目的是用来匹配一个用“/”分隔符组成的字符串，比如“/a/b/c”，按前文所述，此正则表达式违犯了规则1：它包括嵌套的量词。

如果请求端请求了一个这样的字符串：///.../\n(100个'/'，然后跟一个换行符'\n'，这个换行符不会匹配上)，然后事件循环便会一直满载并阻塞后续的步骤(此时正则会进行2^100次匹配)，客户端的这次ReDoS攻击会得在其它所有客户端在这个正则匹配完成前都不会得到处理的机会。

因此，

#### 防止REDOS的资源

* safe-regex
* rxxr2

但这两个工具也不能检测出所有的易受攻击的正则表达式。另一个方式就是使用别的正则引擎，比如node-re2模块，它使用了谷歌的高效正则引擎——RE2，但需要注意的是，它并不能100%适配Node的正则，部分复杂的正则表达式也不被支持。如果你是用来匹配一些觉的场景，比如URL、文件路径、IP地址之类的，可以找一些现成的例子或对应的npm模块，比如ip-regex等。

### 阻塞事件循环：Node核心模块

部分Node的核心模块有一些同步的耗时较多的API，这包括加密、压缩、文件系统以及子进程。这些API之所以耗时，是因为它们涉及大量的计算，这些API旨在为脚本编写提供便利，并不是为了在服务端上下文中使用。如果在事件循环中使用它们，则调用完成的耗时要比典型的javascript指令多得多，从而会阻塞事件循环。

在服务器上，不应该使用如下模块中的同步API：

* 加密：
	* crypto.randomBytes（同步版本）
	* crypto.randomFillSync
	* crypto.pbkdf2Sync
	* 同时需要注意的是，加解密时最好不要传递大量的输入
* 压缩
	* zlib.inflateSync
	* zlib.deflateSync
* 文件系统
	* 不要使用同步调用的文件系统API，比如，如果你访问的文件是在类似于NFS的分布式文件系统上，那访问耗时的变化就会非常大（网络因素）
* 子进程
	* child_process.spawnSync
	* child_process.execSync
	* child_process.execFileSync

### 阻塞事件循环：JSON DOS

JSON.parse和JSON.stringify是潜在的耗时多的操作，尽管时间复杂度为O(n)，和输入的长度相关，当n非常大时，耗时也是相当久。

如果你的服务器操作JSON对象，特别是来自于客户端的，在事件循环中就需要注意一下JSON对象或字符串的长度。

有一些npm模块提供异步的JSON API来处理这种场景：

* JSONStream，提供流式处理的API
* Big-Friendly JSON，它提供了标准JSON API的异步流式的版本，是基于下面要提到的事件循环分片的规范

### 不阻塞事件循环实现复杂计算的方法

在javascript中，想进行复杂计算，又不想阻塞事件循环，你有两个选择：分片或转移（不在事件循环上进行处理）

#### 分片

你可以将你的计算进行分片，每个分片在事件循环上执行固定的时间，来给别的挂起的事件执行的机会。在javascript中通过闭包来保存一个正在执行的任务的状态是一件容易的事，就像下面的这个例子。

```javascript
// 未分片的版本，时间复杂度O(n)
for (let i = 0; i < n; i++)
  sum += i;
let avg = sum / n;
console.log('avg: ' + avg);

// 分片的版本，每次执行的时间复杂度O(1)
function asyncAvg(n, avgCB) {
  // Save ongoing sum in JS closure.
  var sum = 0;
  function help(i, cb) {
    sum += i;
    if (i == n) {
      cb(sum);
      return;
    }

    // "Asynchronous recursion".
    // Schedule next operation asynchronously.
    setImmediate(help.bind(null, i+1, cb));
  }

  // Start the helper, with CB to call avgCB.
  help(1, function(sum){
      var avg = sum/n;
      avgCB(avg);
  });
}

asyncAvg(n, function(avg){
  console.log('avg of 1-n: ' + avg);
});
```

你可以将这个原理应用于数组的迭代等等。

#### 转移

如果你需要做一些更复杂的事，并且分片不是一个好的选择，因为分片仅仅是使用事件循环，却不能充分多核CPU优势（假设你的机器满足这个前提），记住，事件循环只应该进行客户端请求的编排，而不是自己去完成它们。对于一个复杂的任务，将这个工作交给工作线程池来完成。

* 如何进行？

对于目标工作线程池，你有两种选择，可以将工作转移到其中之一：

1. 可以通过开发C++扩展来使用内建的Node工作线程池，对于老版本的Node使用NAN来开发，新版的则使用N-API。node-webworker-threads提供了一个仅javascript可用的方式来访问Node的工作线程池。
2. 可以创建并管理自己的工作线程池专门用于进行计算，而不是使用Node的主要面向I/O操作的线程池。最直接的方法就是使用子进程（Child Process）和集群（Cluster）

这并表示应该简单的为每一个客户端都创建一个子进程。因为相对创建和管理子进程来说，接收客户端的请求要快得多，如果这样做（每个客户端创建一个子进程），你的服务器将会变成一个“fork bomb“。

* 缺点

这种方法的缺点是会增加通信上的开销。对于工作线程而言，它是无法直接操作事物循环中的javascript对象，要实现任何对象的共享，必须进行对应的序列化与反序列化，工作线程操作的是这些对象的复制版本，操作完成后，以同样的方式将结果返回给事件循环。关于序列化这块，可以参见上述章节。

* 建议

首先需要区分是CPU密集型任务还是I/O密集型任务，因为它们有着显著的不同的特征。

对于CPU密集型的任务，因为只有在工作线程被服务器的逻辑内核调度时，它才会开始处理，也就是说，如果你的机器的逻辑内核数为4，当前有5个工作线程，其中有一个工作线程是没在工作的，其结果就是你为这个工作线程付出了开销（内核分配，调度）但却无法得到任何结果。

I/O密集型任务主要涉及对外部服务提供者的查询（DNS，文件系统等）以及等待响应结果。当一个进行I/O密集型任务的工作线程等待它的响应时，它没有别的事可做，则可以被操作系统取消调度，从而给其它的工作线程提交请求的机会。因此，即使关联的线程不是运行状态，I/O密集型任务也可以正常进行。像数据库和文件系统这样的外部服务提供者都经过高度优化来同时处理多个挂起的请求。比如，一个文件系统将检查一组挂起的写和读请求，以合并冲突的更新并以最佳顺序检索文件。

如果你只依赖于一个工作线程池，比如Node的工作线程池，那么CPU密集型任务与I/O密集型任务的不同特征可能会损害你应用的性。所以你最好维护一个独立的用于计算的工作线程池。

* 结论

对于简单的任务，比如对一个长的数组进行元素迭代，分片处理是一个好的选择。如果有复杂的计算，那么转移则是一个更好的选择：通信成本（在工作线程池与事件循环之间传递序列化的对象）会被充分复用多核的好处抵消。

但是，如果你的服务依赖于重度复杂的计算，你就需要考虑一下Node是否合适，Node擅长I/O相关的工作，但对于复杂计算类的工作，它可能并不是一个最好的选择。

## 不要阻塞工作线程池

Node拥有一个由k个工作线程组成的工作线程池，如果你使用上文讨论的转移规范，你可能还有一个独立的用于计算的工作线程池，它同样也是由k个工作线程组成，无论哪一种方案，我们假设k是一个远小于你要并行处理的客户端的数量。这符合Node的“一个线程多个客户端”的设计哲学（也是它可伸缩性的秘诀）。

如上文讨论，线程池中的每个工作线程处理完当前的任务后接着处理下一个。

现在，处理客户端请求任务的成本是变化的。一些任务能很快的完成，而另一些则需要更久，你的目标则是最大程度的减少任务耗时的变化，使用任务分片可以实现此目标。

### 尽可能减少任务时间的变化

如果一个工作线程当前任务比其它的耗时更久，那么它就没有能力去处理别的挂起的任务，换言之，每一个耗时长的任务都会使当前工作线程池的大小减少1直到这个任务完成。这种场景是不希望看到的，因为在某种程序上，工作线程池中的线程数越多，其吞吐量越大（每秒处理的任务数），服务器的吞吐量也越大（每秒处理的客户端请求数），反之亦然。

为了避免此种情况，你应该尽量减少提交给工作线程池的任务的耗时，尽管将你的I/O请求访问外部系统的过程视作黑盒更为合适，但你还是应当了解这些I/O请求的耗时，并且尽量避免提交一些你预估耗时会很长的请求。

下面有两个例子来说明任务时长可能变化

* 耗时长的文件读取

假设你的服务器为了处理客户端的请求必须读取文件，在参考Node的文件系统API之后，出于简单起见，你选择使用fs.readFile()，然而这个API并不是分片执行的（具体指对应版本的Node文档而定，可能新版本中进行了修改）：它提交了一个fs.read()任务来扫描整个文件，如果部分用户读取的文件比较小，而另一部分读取的是大文件，而fs.readFile()会在任务的耗时上带来非常大的变动，从而影响线程池的吞吐量。

最坏的情况，攻击者可以利用漏洞让服务器读取任务的文件（目录扫描漏洞），如果你的服务器是Linux，攻击者可以指定一个超级慢的文件（/dev/random）去访问，出于一些实际的目的，/dev/random会无限的慢，而读取此文件的工作线程永远不会完成。如果攻击者提交了k次请求，每个线程都处理一个请求，则其它所有使用线程池的请求都被阻塞（没有可用的线程去处理任务了）。

* 耗时长的加密操作

假设你的服务器使用crypto.randomBytes()来生成密级安全的随机字节。crypto.randomBytes也不是分片执行的，所以如果你为不同的用户生成的字节长度不一，同样给任务的耗时带来较大的变动。

### 任务分块

任务耗时的变动会影响到线程池的吞吐量。为了减小这个变动，应该尽可能的将每个任务拆分成耗时相近的子任务。每一个子任务完成后，它需要提交下一个子任务，当最后一个子任务完成时，它需要通知提交者。

来继续看fs.readFile()的例子，应当使用fs.read()（手动分片）或ReadStream（自动分片）。此方法同样适用到CPU密集型任务；前文asyncAvg（求平均数）的例可能不适合事件循环，但却十分适合工作线程池。

当你将任务切分成子任务时，对于短任务，切分的子任务数较少，对于长任务则切分的子任务较多，对于一个长任务的子任务，分配来处理它的工作线程也可以用于处理另一个短任务的子任务，从而提升整个工作线程池的吞吐量。

需要注意的事，子任务的完成数量不能作为工作线程池吞吐量的一个指标。相反，你应该关注完成的任务数量。

### 避免任务分块的场景

回想一下，任务分块的目的是最小化任务耗时的变化。如果你可以区分出短任务与长任务，你可以为每一类任务创建一个工作线程池，将短任务与长任务分配到独立的线程池是另一种最小化任务耗时变化的方式。

更推荐此方法，任务分块会带来开销（创建工作线程池中任务的表现形式——子任务以及操作线程池的队列）。而避免分块的方式节约访问工作线程池的次数，同时也可以避免在任务分块时出错。

此方法的缺点是所有这些线程池中的工作线程会产生空间和时间上的开销，并且会相互竞争CPU时间。请记住，每一个CPU关联的任务，只有在获取CPU时间片进行调度时才会进行，因为在你考虑使用此方法前要经过仔细的分析。

### 结论

无论是使用Node的工作线程池，还是维护独立的线程池，你都需要优化线程池的吞吐量。为了实现它，通过使用任务分块来尽量可能最小化任务耗时的变动。

## npm模块的风险

尽管Node的核心模块为各种应用提供了构建基块，但有时这往往不够。Node的开发者从npm生态系统上成百上千的模块提供的功能中获益，大大加速了开发的进度。

但有一点你要记住，这些模块中的很大部分都是第三方开发者写的，并且也仅仅是尽可能努力保证的发布版本。使用npm上模块的开发者需要关注两件事，尽管后者经常被遗忘：

1. 它是否遵循了它的API文档
2. 它的API会阻塞事件循环或线程吗？很多模块没有说明他们API的开销

对于简单的API你可能可以评估出API的开销，字符串操作的耗时也不并难理解。但有很多场景，API的开销可能不是那么显而易见的

如果你调用的API可能做一些开销很大的事，需要核查它的开销。要求开发者提供文档，或者自己检查源码并提供一个PR来说明其开销。

记住，即使API是异步的，你还是不知道在它每部分在事件循环或线程上的耗时。举个例子，假设上文提到的asyncAvg的例子中，每次对helper函数的调用都是计算一半元素的累加和，那么这个函数尽管每部分的耗时复杂度是O(n)而不是O(1)，那么对于n的任意值，可能不能保证这个方法可以安全的调用。

## 总结

Node有两种类型的线程：一个事件循环和k个工作线程。前者主要负责执行javascript的回调和非阻塞的I/O操作，而工作线程则是执行C++代码对应的任务，包括阻塞的I/O操作以及CPU密集型操作。两种类型的线程每次只能执行一个活动。如果任务的回调或任务耗时很长，那这个线程就会被阻塞。如果你的应用进行阻塞的回调或任务，情况好一点时只是导致吞吐量的降低，最差时会导致拒绝服务。

要编写高吞吐量、更可靠的web服务，你需要确保对于良性或恶性的输入，你的事件循环或线程都不会被阻塞。